# ğŸ§ª Lab: 103.2 Process Text Streams Using Filters

## ğŸ¯ What I Did in This Lab  
I worked hands-on with various text filter commands such as `cut`, `sort`, `uniq`, `wc`, and `sed`. I simulated real-world use cases by creating and manipulating text files, sorting and transforming content, and verifying checksums. ğŸ§©

Iâ€™ve included some helpful links to guide you through the lab and for studying afterward:

- [LPIC-1 EXAM OBJECTIVE](https://www.lpi.org/our-certifications/exam-101-102-objectives/#103.2_Process_text_streams_using_filters)  
- []  
- []  

---

## 1ï¸âƒ£ Filter and Display Basic File Content  
ğŸ”¹ Explore basic file reading and redirection  

## 2ï¸âƒ£ Modify and Analyze Output Streams  
ğŸ”¹ Use various commands to modify how text is displayed  

## 3ï¸âƒ£ Stream Text Through Filters  
ğŸ”¹ Apply filters to transform, clean, and sort data  

## 4ï¸âƒ£ Split, Combine, and Manipulate Files  
ğŸ”¹ Break files apart and glue them back together  

## 5ï¸âƒ£ Checksum and Compression Filters  
ğŸ”¹ Use hashing and view compressed files  

---

## ğŸ§  What I Learned  
This lab taught me how to effectively manipulate text streams using a wide range of filters and utilities. I learned how to analyze file content, format output, transform text, and even verify file integrity with hash functions. ğŸ’¡ These tools are incredibly useful in real-world sysadmin and scripting tasks!
